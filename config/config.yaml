################# Training Control #################
deterministic: False
use_compile: True
seed: 1234
lr: 1e-3
max_epochs: 100
lr_scheduler: step
lr_decay_epochs: 10
lr_decay_rate: 0.5
lr_decay_min_lr: 1e-6

################# Distributed Training Control #################
devices: 1
num_nodes: 1
strategy: auto

################# Dataset Setting #################
dataset_class_name: coco
dataset_dir: dataset
split_ratios: [0.8, 0.1, 0.1]
batch_size: 32
num_workers: 8
persistent_workers: True

################# Model Architecture, Optimizers and Loss Functions #################
# Basic setting
model_class_name: lg_baseline
weight_decay: 1e-6

# VQVAE model setting
h_dim: 128
res_h_dim: 32
n_res_layers: 2
n_embeddings: 1024
embedding_dim: 64
beta: 0.25
save_img_embedding_map: False

# Transformer model setting
src_vocab_size: 10000
tgt_vocab_size: 1024
d_model: 512
num_heads: 8
num_encoder_layers: 4
num_decoder_layers: 4
dim_ff: 1024
dropout: 0.1
max_len: 512

################# Tensorboard Logger Setting #################
log_dir: 'lightning_logs'
experiment_name: 'main'

################# Checkpoint & Restart Control #################
enable_checkpointing: True