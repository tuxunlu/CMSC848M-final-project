################# Training Control #################
deterministic: False
use_compile: True
seed: 1234
lr: 1e-3
max_epochs: 100
lr_scheduler: step
lr_decay_epochs: 10
lr_decay_rate: 0.5
lr_decay_min_lr: 1e-6

################# Distributed Training Control #################
devices: 1
num_nodes: 1
strategy: ddp

################# Dataset Setting #################
dataset_class_name: coco
dataset_dir: dataset
split_ratios: [0.8, 0.1, 0.1]
batch_size: 2
num_workers: 8
persistent_workers: True
img_dir: data/coco/images
ann_dir: data/coco/annotations

################# Model Architecture, Optimizers and Loss Functions #################
# Basic setting
model_class_name: baseline
weight_decay: 1e-6

# VQVAE model setting
pretrained_vqvae_path: model_state_dict.pth
h_dim: 128
res_h_dim: 128
n_res_layers: 4
n_embeddings: 1024
embedding_dim: 128
beta: 0.25
save_img_embedding_map: False

# Transformer model setting
src_vocab_size: 2000
tgt_vocab_size: 1200
d_model: 512
num_heads: 8
num_encoder_layers: 2
num_decoder_layers: 2
dim_ff: 512
dropout: 0.1
max_len: 256

################# Tensorboard Logger Setting #################
log_dir: 'lightning_logs'
experiment_name: 'main'

################# Checkpoint & Restart Control #################
enable_checkpointing: True